#!/home/johannes/miniconda3/bin/python

import argparse
from pathlib import Path
import torch
torch.set_num_threads(1)

from IPython.display import Audio

parser = argparse.ArgumentParser("Extract the segment timestamps of audible speech.")
parser.add_argument('file', type=Path)
args = parser.parse_args()

model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',
                              model='silero_vad',
                              force_reload=True)

(get_speech_timestamps, _, read_audio, *_) = utils

sampling_rate = 16000 # also accepts 8000
wav = read_audio(args.file, sampling_rate=sampling_rate)

speech_timestamps = get_speech_timestamps(wav, model, sampling_rate=sampling_rate)
for segment in speech_timestamps:
    start = segment['start'] / sampling_rate
    end = segment['end'] / sampling_rate
    print(f"{start}s,{end}s", end=' ')

